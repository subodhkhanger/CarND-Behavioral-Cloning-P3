{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpumodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subodhkhanger/CarND-Behavioral-Cloning-P3/blob/master/tpumodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "v5GJVvLgDHRU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# command line flags\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cameras = ['left', 'center', 'right']\n",
        "camera_centre = ['center']\n",
        "steering_adj = {'left': 0.25, 'center': 0., 'right': -.25}\n",
        "\n",
        "\n",
        "#using open cv function to load image \n",
        "def loadImg(imgLoc,trainFile):\n",
        "    filename = trainFile.strip()\n",
        "    if filename.startswith('IMG'):\n",
        "        filename = imgLoc+'/'+filename\n",
        "    else:\n",
        "        # load it relative to where log file is now, not whats in it\n",
        "        filename = imgLoc+'/IMG/'+PurePosixPath(filename).name\n",
        "    img = cv2.imread(filename)\n",
        "   \n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "\n",
        "def brightness(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    bv = .25 + np.random.uniform()\n",
        "    hsv[::2] = hsv[::2]*bv\n",
        "\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "\n",
        "def crop_img(img, crop_height=66, crop_width=200):\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    y_start = 60\n",
        "    x_start = int(width/2)-int(crop_width/2)\n",
        "\n",
        "    return img[y_start:y_start+crop_height, x_start:x_start+crop_width]\n",
        "\n",
        "\n",
        "\n",
        "def imagerotation(image, steering):\n",
        "    rows, cols, _ = image.shape\n",
        "    transRange = 100\n",
        "    numPixels = 10\n",
        "    valPixels = 0.4\n",
        "    transX = transRange * np.random.uniform() - transRange/2\n",
        "    steering = steering + transX/transRange * 2 * valPixels\n",
        "    transY = numPixels * np.random.uniform() - numPixels/2\n",
        "    transMat = np.float32([[1, 0, transX], [0, 1, transY]])\n",
        "    image = cv2.warpAffine(image, transMat, (cols, rows))\n",
        "    return image, steering\n",
        "\n",
        "\n",
        "\n",
        "def straightdriving(data_df, hist_items=5):\n",
        "    print('filtering straight line driving with %d frames consective' %\n",
        "          hist_items)\n",
        "    steering_history = deque([])\n",
        "    drop_rows = []\n",
        "\n",
        "    for idx, row in data_df.iterrows():\n",
        "        \n",
        "        steering = getattr(row, 'steering')\n",
        "\n",
        "       \n",
        "        steering_history.append(steering)\n",
        "        if len(steering_history) > hist_items:\n",
        "            steering_history.popleft()\n",
        "\n",
        "       \n",
        "        if steering_history.count(0.0) == hist_items:\n",
        "            drop_rows.append(idx)\n",
        "\n",
        "    \n",
        "    return data_df.drop(data_df.index[drop_rows])\n",
        "\n",
        "\n",
        "\n",
        "def cameraimage(row, log_path, cameras):\n",
        "    steering = getattr(row, 'steering')\n",
        "   \n",
        "    camera = cameras[random.randint(0, len(cameras)-1)]\n",
        "   \n",
        "    steering += steering_adj[camera]\n",
        "\n",
        "    image = loadImg(log_path, getattr(row, camera))\n",
        "    image, steering = imagerotation(image, steering)\n",
        "    image = brightness(image)\n",
        "\n",
        "    return image, steering\n",
        "\n",
        "\n",
        "\n",
        "def gen_train_data(log_path='./data', log_file='driving_log.csv', skiprows=1,\n",
        "                   cameras=cameras, filter_straights=False,\n",
        "                   crop_image=True, batch_size=128):\n",
        "\n",
        "    # load the csv log file\n",
        "    print(\"Cameras: \", cameras)\n",
        "    print(\"Log path: \", log_path)\n",
        "    print(\"Log file: \", log_file)\n",
        "\n",
        "    column_names = ['center', 'left', 'right',\n",
        "                    'steering', 'throttle', 'brake', 'speed']\n",
        "    data_df = pd.read_csv(log_path+'/'+log_file,\n",
        "                          names=column_names,skiprows=1)\n",
        "    \n",
        "    print(filter_straights)\n",
        "    if filter_straights:\n",
        "        data_df = filter_driving_straight(data_df)\n",
        "\n",
        "    data_count = len(data_df)\n",
        "\n",
        "    print(\"Log with %d rows.\" % (len(data_df)))\n",
        "    i=0\n",
        "    while (i<100):  # need to keep generating data\n",
        "\n",
        "        # initialise data extract\n",
        "        features = []\n",
        "        labels = []\n",
        "        \n",
        "        # create a random batch to return\n",
        "        while len(features) < batch_size:\n",
        "            #print(features)\n",
        "            row = data_df.iloc[np.random.randint(data_count-1)]\n",
        "            i+=i\n",
        "            image, steering = cameraimage(row, log_path, cameras)\n",
        "\n",
        "            # flip 50% randomily that are not driving straight\n",
        "            if random.random() >= .5 and abs(steering) > 0.1:\n",
        "                image = cv2.flip(image, 1)\n",
        "                steering = -steering\n",
        "\n",
        "            if crop_image:\n",
        "                image = crop_img(image)\n",
        "\n",
        "            features.append(image)\n",
        "            labels.append(steering)\n",
        "\n",
        "        # yield the batch\n",
        "        yield (np.array(features), np.array(labels))\n",
        "\n",
        "\n",
        "# create a valdiation data generator for keras fit_model\n",
        "def gen_val_data(log_path='/u200/Udacity/behavioral-cloning-project/data',\n",
        "                 log_file='driving_log.csv', camera=camera_centre[0],\n",
        "                 crop_image=True, skiprows=1,\n",
        "                 batch_size=128):\n",
        "\n",
        "    # load the csv log file\n",
        "    print(\"Camera: \", camera)\n",
        "    print(\"Log path: \", log_path)\n",
        "    print(\"Log file: \", log_file)\n",
        "\n",
        "    column_names = ['center', 'left', 'right',\n",
        "                    'steering', 'throttle', 'brake', 'speed']\n",
        "    data_df = pd.read_csv(log_path+'/'+log_file,\n",
        "                          names=column_names, skiprows=skiprows)\n",
        "    data_count = len(data_df)\n",
        "    print(\"Log with %d rows.\"\n",
        "          % (data_count))\n",
        "\n",
        "    while data_count:  # need to keep generating data\n",
        "\n",
        "        # initialise data extract\n",
        "        features = []\n",
        "        labels = []\n",
        " \n",
        "        # create a random batch to return\n",
        "        while len(features) < batch_size:\n",
        "            #print(features)\n",
        "            row = data_df.iloc[np.random.randint(data_count-1)]\n",
        "            steering = getattr(row, 'steering')\n",
        "           \n",
        "            # adjust steering if not center\n",
        "            steering += steering_adj[camera]\n",
        "\n",
        "            image = loadImg(log_path, getattr(row, camera))\n",
        "\n",
        "            if crop_image:\n",
        "                image = crop_img(image)\n",
        "\n",
        "            features.append(image)\n",
        "            labels.append(steering)\n",
        "\n",
        "        # yield the batch\n",
        "        yield (np.array(features), np.array(labels))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_nvidia_model(img_height=66, img_width=200, img_channels=3,\n",
        "                       dropout=.4):\n",
        "\n",
        "    \n",
        "    # normalisation layer\n",
        "    inputShape = (img_height, img_width, img_channels)\n",
        "    #model.add(Lambda(lambda x: x * 1./127.5 - 1,\n",
        "    #                 input_shape=(img_shape),\n",
        "     #                output_shape=(img_shape), name='Normalization'))\n",
        "    \n",
        "    \n",
        "        # my architecture \n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Lambda(lambda x: x/255.-0.5,input_shape=inputShape))\n",
        "    model.add(tf.keras.layers.Conv2D(3,1,1, activation = 'elu', name='Conv2D1')) # color space \n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16,8,8, activation = 'elu', name='Conv2D2'))\n",
        "    #model.add(Conv2D(16,9,9, activation = 'elu', name='Conv2D2'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), name='MaxPoolC2'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3, name='DropoutC2'))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32,5,5, activation = 'elu', name='Conv2D3'))\n",
        "    #model.add(Conv2D(32,7,7, activation = 'elu', name='Conv2D3'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), name='MaxPoolC3'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3, name='DropoutC3'))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32,3,3, activation = 'elu', name='Conv2D4'))\n",
        "    #model.add(Conv2D(128,3,3, activation = 'elu', name='Conv2D5'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), name='MaxPoolC4'))\n",
        "    model.add(tf.keras.layers.Dropout(0.3, name='DropoutC4'))\n",
        "\n",
        "    #model.add(Conv2D(64,3,3, activation = 'elu', name='Conv2D5'))\n",
        "    #model.add(Conv2D(128,3,3, activation = 'elu', name='Conv2D6'))\n",
        "    #model.add(MaxPooling2D(pool_size=(2,2), name='MaxPoolC6'))\n",
        "    #model.add(Dropout(0.5, name='DropoutC6'))\n",
        "\n",
        "    #model.add(Conv2D(256,2,2, activation = 'relu', name='Conv2D7'))\n",
        "    #model.add(MaxPooling2D(pool_size=(2,2), name='MaxPoolC7'))\n",
        "    #model.add(Dropout(0.5, name='DropoutC7'))\n",
        "\n",
        "    # convolution to dense\n",
        "    model.add(tf.keras.layers.Flatten(name='Conv2Dense'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(256,activation='elu', name='Dense1'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5, name='DropoutD1'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(128,activation='elu', name='Dense2'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5, name='DropoutD2'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(64,activation='elu', name='Dense3'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5, name='DropoutD3'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(8,activation='elu', name='Dense4'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5, name='DropoutD4'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1,activation='elu', name='Output'))\n",
        "\n",
        " \n",
        "   \n",
        "\n",
        "    optimizer = tf.train.Adam(lr=0.001)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='mse')\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_callbacks():\n",
        "    # checkpoint = ModelCheckpoint(\n",
        "    #     \"checkpoints/model-{val_loss:.4f}.h5\",\n",
        "    #     monitor='val_loss', verbose=1, save_weights_only=True,\n",
        "    #     save_best_only=True)\n",
        "\n",
        "    # tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
        "    #                           write_graph=True, write_images=False)\n",
        "\n",
        "    # return [checkpoint, tensorboard]\n",
        "\n",
        "    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0,\n",
        "                                  patience=1, verbose=1, mode='auto')\n",
        "    # return [earlystopping, checkpoint]\n",
        "    return [earlystopping]\n",
        "\n",
        "\n",
        "def run():\n",
        "  \n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  training_model = build_nvidia_model()\n",
        "\n",
        "  tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "      training_model,\n",
        "      strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "          tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "  tpu_model.fit_generator(\n",
        "      gen_train_data(log_path='./data',\n",
        "                       cameras=cameras,\n",
        "                       #    cameras=camera_centre,\n",
        "                       crop_image=True,\n",
        "                       batch_size=28\n",
        "                       ),\n",
        "      steps_per_epoch=20000,\n",
        "      epochs=3,\n",
        "      validation_data=gen_val_data(log_path='./data',\n",
        "                                     crop_image=True,\n",
        "                                     batch_size=28),\n",
        "        nb_val_samples=5000\n",
        "  )\n",
        "  tpu_model.save_weights('/tmp/bard.h5', overwrite=True)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def main():\n",
        "\n",
        "    \n",
        "    model = build_nvidia_model()\n",
        "    \n",
        "    print(model.summary())\n",
        "\n",
        "    #plot(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "    model.fit_generator(\n",
        "        gen_train_data(log_path='./data',\n",
        "                       cameras=cameras,\n",
        "                       #    cameras=camera_centre,\n",
        "                       crop_image=True,\n",
        "                       batch_size=28\n",
        "                       ),\n",
        "        samples_per_epoch=20000,\n",
        "        nb_epoch=3,\n",
        "        #callbacks=get_callbacks(),\n",
        "        validation_data=gen_val_data(log_path='./data',\n",
        "                                     crop_image=True,\n",
        "                                     batch_size=28),\n",
        "        nb_val_samples=5000)\n",
        "\n",
        "    # save weights and model\n",
        "    model.save('model.h5')\n",
        "    with open('model.json', 'w') as modelfile:\n",
        "        json.dump(model.to_json(), modelfile)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StXK0tRODi8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from collections import deque\n",
        "from scipy.stats import norm\n",
        "import random\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAbVv94tGXcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "44c99583-d22c-4d27-ffcf-0945c213e464"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    run()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-41f627089c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-8a75c62f546d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m   \u001b[0mtraining_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_nvidia_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
            "\u001b[0;32m<ipython-input-12-8a75c62f546d>\u001b[0m in \u001b[0;36mbuild_nvidia_model\u001b[0;34m(img_height, img_width, img_channels, dropout)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'elu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Conv2D2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m#model.add(Conv2D(16,9,9, activation = 'elu', name='Conv2D2'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MaxPoolC2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DropoutC2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.keras.layers' has no attribute 'MaxPooling'"
          ]
        }
      ]
    }
  ]
}